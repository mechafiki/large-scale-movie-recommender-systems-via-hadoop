{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Required installations"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install gdown\n","!pip install pyspark"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Required imports"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T20:57:22.081535Z","iopub.status.busy":"2023-05-28T20:57:22.081132Z","iopub.status.idle":"2023-05-28T20:57:22.868118Z","shell.execute_reply":"2023-05-28T20:57:22.867068Z","shell.execute_reply.started":"2023-05-28T20:57:22.081498Z"},"trusted":true},"outputs":[],"source":["from pyspark.sql import SparkSession\n","import pyspark.sql.functions as F\n","from pyspark.ml.clustering import KMeans\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.sql.functions import col\n","from sklearn.metrics import recall_score, precision_score, f1_score,mean_squared_error\n","from sklearn.metrics.pairwise import cosine_similarity\n","import pandas as pd\n","import numpy as np"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Spark Session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T20:57:27.138437Z","iopub.status.busy":"2023-05-28T20:57:27.138052Z","iopub.status.idle":"2023-05-28T20:57:33.620241Z","shell.execute_reply":"2023-05-28T20:57:33.618862Z","shell.execute_reply.started":"2023-05-28T20:57:27.138397Z"},"trusted":true},"outputs":[],"source":["spark = SparkSession.builder \\\n","        .master(\"local[*]\") \\\n","        .appName(\"Recommender\") \\\n","        .config(\"spark.driver.memory\", \"16g\") \\\n","        .config(\"spark.executor.memory\", \"16g\") \\\n","        .getOrCreate()\n","\n","spark.conf.set(\"spark.sql.pivotMaxValues\", \"71567\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load and format the ratings data\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 100k"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T20:57:39.088518Z","iopub.status.busy":"2023-05-28T20:57:39.088119Z","iopub.status.idle":"2023-05-28T20:57:47.507399Z","shell.execute_reply":"2023-05-28T20:57:47.506257Z","shell.execute_reply.started":"2023-05-28T20:57:39.088479Z"},"trusted":true},"outputs":[],"source":["!gdown 1lwPW7OefaJnwsaqYBQs-wgcIGiatYLXb\n","\n","def load_100k() :\n","    data = spark.read.option(\"delimiter\", \"\\t\")\\\n","                    .option(\"header\", \"False\")\\\n","                    .csv('/kaggle/working/u.data')\\\n","                    .select('_c0','_c1','_c2')\\\n","                    .withColumnRenamed('_c0','userId')\\\n","                    .withColumnRenamed('_c1', 'movieId') \\\n","                    .withColumnRenamed('_c2', 'rating')\n","    data = data.select([F.col(c).cast(\"int\") for c in data.columns])\n","    return data\n","    \n","ratings_df = load_100k()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 1M"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T21:03:00.212810Z","iopub.status.busy":"2023-05-28T21:03:00.212416Z","iopub.status.idle":"2023-05-28T21:03:04.208566Z","shell.execute_reply":"2023-05-28T21:03:04.207254Z","shell.execute_reply.started":"2023-05-28T21:03:00.212777Z"},"trusted":true},"outputs":[],"source":["!gdown 18sHWE7Eu28hDqXib2PvesBYMea5AQmZs\n","\n","def load_1m() :\n","    data = spark.read.option(\"delimiter\", \"::\")\\\n","                    .option(\"header\", \"False\")\\\n","                    .csv('/kaggle/working/ratings.dat')\\\n","                    .select('_c0','_c1','_c2')\\\n","                    .withColumnRenamed('_c0','userId')\\\n","                    .withColumnRenamed('_c1', 'movieId') \\\n","                    .withColumnRenamed('_c2', 'rating')\n","    data = data.select([F.col(c).cast(\"int\") for c in data.columns])\n","    return data\n","    \n","ratings_df = load_1m()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 10M"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!gdown 1e064MFX83PYtPDcISjYQw4fTQtv-PG38\n","\n","def load_10m() :\n","    data = spark.read.option(\"delimiter\", \"::\")\\\n","                    .option(\"header\", \"False\")\\\n","                    .csv('/kaggle/working/ratings.dat')\\\n","                    .select('_c0','_c1','_c2')\\\n","                    .withColumnRenamed('_c0','userId')\\\n","                    .withColumnRenamed('_c1', 'movieId') \\\n","                    .withColumnRenamed('_c2', 'rating')\n","    data = data.select([F.col(c).cast(\"int\") for c in data.columns])\n","    return data\n","    \n","ratings_df = load_10m()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Split/Train/Test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T21:03:17.187370Z","iopub.status.busy":"2023-05-28T21:03:17.186971Z","iopub.status.idle":"2023-05-28T21:27:03.977756Z","shell.execute_reply":"2023-05-28T21:27:03.976920Z","shell.execute_reply.started":"2023-05-28T21:03:17.187333Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Split Data into train and test\n","train, test = ratings_df.randomSplit([0.9,0.1],1111)\n","\n","# Convert the ratings data to a matrix where rows are users and columns are movies\n","ratings_matrix = train.groupBy(\"userId\").pivot(\"movieId\").agg({\"rating\": \"avg\"}).na.fill(0)\n","# Convert the matrix to a feature vector using VectorAssembler\n","assembler = VectorAssembler(inputCols=ratings_matrix.columns[1:], outputCol=\"features\")\n","features_df = assembler.transform(ratings_matrix).select(\"userId\", \"features\")\n","# Run KMeans clustering to create clusters of users based on their movie rating patterns\n","kmeans = KMeans(k=10, maxIter=10, tol=0.1, seed=123,distanceMeasure='cosine')\n","model = kmeans.fit(features_df)\n","cluster_assignments = model.transform(features_df).select(\"userId\", \"prediction\")\n","\n","# Join the cluster assignments with the original ratings dataframe\n","ratings_df_with_clusters = ratings_df.join(cluster_assignments, on='userId')\n","\n","# Split the ratings dataframe into separate dataframes for each cluster\n","num_clusters = cluster_assignments.select('prediction').distinct().count()\n","cluster_dfs = []\n","for i in range(num_clusters):\n","    cluster_df = ratings_df_with_clusters.filter(f\"prediction = {i}\")\n","    cluster_dfs.append(cluster_df)\n","\n","matrices = {}\n","#Loop through each cluster DataFrame\n","for i in range(num_clusters):\n","    # Get the ratings DataFrame for the current cluster\n","    cluster_df = cluster_dfs[i]\n","    matrix = cluster_df.toPandas().pivot_table(index='userId', columns='movieId', values='rating')\n","    matrices[i] = pd.DataFrame(cosine_similarity(matrix.fillna(0)) , index = matrix.index , columns = matrix.index)  \n","\n","clustered_ratings_pd=ratings_df_with_clusters.toPandas()\n","ratings_df_pd = ratings_df.toPandas()\n","predictions = []\n","for row in test.collect():\n","    # Get user and movie ids\n","    user_id = row['userId']\n","    movie = row['movieId']\n","    # Get cluster id\n","    cluster = clustered_ratings_pd.loc[clustered_ratings_pd['userId'] == user_id, 'prediction']\n","    # Check if no cluster is assigned to current user\n","    if cluster.empty :\n","        predictions.append(None)\n","    else :\n","        cluster_id = cluster.values[0]\n","        # Get the N closest neighbors for the user\n","        N = 10\n","        neighbors = matrices[cluster_id][user_id].sort_values(ascending=False)[1:N+1]\n","        # Filter the ratings dataframe to get only the ratings for the given movie and neighbor IDs\n","        filtered_ratings_df = ratings_df_pd[(ratings_df_pd['userId'].isin(neighbors.index.tolist())) & (ratings_df_pd['movieId'] == movie)]\n","\n","        if filtered_ratings_df.empty:\n","            predictions.append(None)\n","        else :\n","            ratings = filtered_ratings_df['rating'].to_numpy().tolist()\n","            has_rated = filtered_ratings_df['userId'].to_numpy().tolist()\n","            similarities = neighbors[has_rated].values\n","            if np.sum(np.array(similarities)) == 0:\n","                predictions.append(None)\n","            else :\n","                predictions.append(np.average(ratings, weights=similarities))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T21:27:03.980250Z","iopub.status.busy":"2023-05-28T21:27:03.979579Z","iopub.status.idle":"2023-05-28T21:27:06.057249Z","shell.execute_reply":"2023-05-28T21:27:06.056154Z","shell.execute_reply.started":"2023-05-28T21:27:03.980208Z"},"trusted":true},"outputs":[],"source":["def fillNa(lst):\n","    non_none_values = [x for x in lst if x is not None]\n","    if len(non_none_values) == 0:\n","        return lst\n","    mean_value = sum(non_none_values) / len(non_none_values)\n","    return [mean_value if x is None else x for x in lst]\n","\n","def create_binarised_output(ratings):\n","    binary = []\n","    for rating in ratings:\n","        if rating >= treshold:\n","            binary.append(1)\n","        else:\n","            binary.append(0)\n","    return binary\n","\n","\n","treshold = 3.5\n","\n","y = test.select('rating').rdd.flatMap(lambda x : x ).collect()\n","\n","filtered_y = []\n","filtered_pred = []\n","\n","for i in range(len(predictions)):\n","    if predictions[i] != None :\n","        filtered_y.append(y[i])\n","        filtered_pred.append(predictions[i])\n","        \n","y_binary = create_binarised_output(filtered_y)\n","pred_binary = create_binarised_output(filtered_pred)\n","\n","# Calcuate RMSE\n","rmse = np.sqrt(mean_squared_error(y, fillNa(predictions)))\n","print(rmse)\n","\n","precision = precision_score(y_binary, pred_binary)\n","print(\"Precision:\", precision)\n","\n","# Calculate recall\n","recall = recall_score(y_binary, pred_binary)\n","print(\"Recall:\", recall)\n","\n","# Calculate f1\n","f1 = f1_score(y_binary, pred_binary)\n","print(\"f1-score:\", f1)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
