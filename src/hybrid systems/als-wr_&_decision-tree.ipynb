{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Required installations"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T19:59:11.622428Z","iopub.status.busy":"2023-05-28T19:59:11.621614Z","iopub.status.idle":"2023-05-28T20:00:18.927575Z","shell.execute_reply":"2023-05-28T20:00:18.926282Z","shell.execute_reply.started":"2023-05-28T19:59:11.622377Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["!pip install gdown\n","!pip install pyspark"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Required imports"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T20:00:18.931761Z","iopub.status.busy":"2023-05-28T20:00:18.931293Z","iopub.status.idle":"2023-05-28T20:00:20.389074Z","shell.execute_reply":"2023-05-28T20:00:20.388057Z","shell.execute_reply.started":"2023-05-28T20:00:18.931706Z"},"trusted":true},"outputs":[],"source":["from pyspark.sql import SparkSession\n","import pyspark.sql.functions as F\n","from pyspark.ml.recommendation import ALS\n","from pyspark.ml.classification import DecisionTreeClassifier\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml import Pipeline\n","from sklearn.metrics import recall_score, precision_score, f1_score,mean_squared_error\n","import numpy as np\n","import math"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Spark Session\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-28T20:01:17.705758Z","iopub.status.busy":"2023-05-28T20:01:17.704970Z","iopub.status.idle":"2023-05-28T20:01:23.218777Z","shell.execute_reply":"2023-05-28T20:01:23.217470Z","shell.execute_reply.started":"2023-05-28T20:01:17.705725Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["spark = SparkSession.builder \\\n","        .master(\"local[*]\") \\\n","        .appName(\"Recommender\") \\\n","        .config(\"spark.driver.memory\", \"16g\") \\\n","        .config(\"spark.executor.memory\", \"16g\") \\\n","        .getOrCreate()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load and format ratings Data\n","\n","### 100k"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T20:01:28.787249Z","iopub.status.busy":"2023-05-28T20:01:28.786825Z","iopub.status.idle":"2023-05-28T20:01:43.857136Z","shell.execute_reply":"2023-05-28T20:01:43.855801Z","shell.execute_reply.started":"2023-05-28T20:01:28.787213Z"},"trusted":true},"outputs":[],"source":["!gdown 1lwPW7OefaJnwsaqYBQs-wgcIGiatYLXb\n","!gdown 1zCAfXEzy9uQYVQWrJ-BpPwQdEUqQaeSK\n","\n","def load_100k() :\n","    data = spark.read.option(\"delimiter\", \"\\t\")\\\n","                    .option(\"header\", \"False\")\\\n","                    .csv('/kaggle/working/u.data')\\\n","                    .select('_c0','_c1','_c2')\\\n","                    .withColumnRenamed('_c0','userId')\\\n","                    .withColumnRenamed('_c1', 'movieId') \\\n","                    .withColumnRenamed('_c2', 'rating')\n","    \n","    movies = spark.read.option(\"delimiter\", \"|\")\\\n","                    .option(\"header\", \"False\")\\\n","                    .csv('/kaggle/working/u.item')\\\n","                    .withColumnRenamed('_c0','movieId')\\\n","                    .drop('_c1','_c2','_c3','_c4')\n","    \n","    data =  data.join(movies, on='movieId')\n","    data = data.select([F.col(c).cast(\"int\") for c in data.columns])\n","    return data\n","    \n","ratings_df = load_100k()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 1M"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T20:17:43.921828Z","iopub.status.busy":"2023-05-28T20:17:43.921322Z","iopub.status.idle":"2023-05-28T20:17:52.542330Z","shell.execute_reply":"2023-05-28T20:17:52.541041Z","shell.execute_reply.started":"2023-05-28T20:17:43.921795Z"},"trusted":true},"outputs":[],"source":["!gdown 18sHWE7Eu28hDqXib2PvesBYMea5AQmZs\n","!gdown 1PtKj4n-sL1PjvbXUqJ_rC_W5MDzQbrgn\n","\n","def load_1m() :\n","    data = spark.read.option(\"delimiter\", \"::\")\\\n","                    .option(\"header\", \"False\")\\\n","                    .csv('/kaggle/working/ratings.dat')\\\n","                    .select('_c0','_c1','_c2')\\\n","                    .withColumnRenamed('_c0','userId')\\\n","                    .withColumnRenamed('_c1', 'movieId') \\\n","                    .withColumnRenamed('_c2', 'rating')\n","    \n","    movies = spark.read.option(\"delimiter\", \",\")\\\n","                    .option(\"header\", \"True\")\\\n","                    .csv('/kaggle/working/movies.csv')\\\n","                    .withColumnRenamed('movie_id','movieId')\\\n","                    .drop('movie_title','release_date','imdb_url')\n","    data =  data.join(movies, on='movieId')\n","    data = data.select([F.col(c).cast(\"int\") for c in data.columns])\n","    return data\n","    \n","ratings_df = load_1m()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 10M"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T20:21:51.223881Z","iopub.status.busy":"2023-05-28T20:21:51.223472Z","iopub.status.idle":"2023-05-28T20:22:06.009944Z","shell.execute_reply":"2023-05-28T20:22:06.008522Z","shell.execute_reply.started":"2023-05-28T20:21:51.223855Z"},"trusted":true},"outputs":[],"source":["!gdown 1e064MFX83PYtPDcISjYQw4fTQtv-PG38\n","!gdown 1lksdO8vXSpkE1DUlXQKsgtLiTQzShF2O\n","\n","def load_10m() :\n","    data = spark.read.option(\"delimiter\", \"::\")\\\n","                    .option(\"header\", \"False\")\\\n","                    .csv('/kaggle/working/ratings.dat')\\\n","                    .select('_c0','_c1','_c2')\\\n","                    .withColumnRenamed('_c0','userId')\\\n","                    .withColumnRenamed('_c1', 'movieId') \\\n","                    .withColumnRenamed('_c2', 'rating')\n","    \n","    movies = spark.read.option(\"delimiter\", \",\")\\\n","                    .option(\"header\", \"True\")\\\n","                    .csv('/kaggle/working/movies.csv')\\\n","                    .withColumnRenamed('movie_id','movieId')\\\n","                    .drop('movie_title','release_date','imdb_url')\n","    data =  data.join(movies, on='movieId')\n","    data = data.select([F.col(c).cast(\"int\") for c in data.columns])\n","    return data\n","    \n","ratings_df = load_10m()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Split/Train/Test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-28T20:24:51.161995Z","iopub.status.busy":"2023-05-28T20:24:51.161564Z","iopub.status.idle":"2023-05-28T20:29:10.584126Z","shell.execute_reply":"2023-05-28T20:29:10.583128Z","shell.execute_reply.started":"2023-05-28T20:24:51.161958Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["train, test = ratings_df.randomSplit([0.9,0.1])\n","\n","# ALS\n","als = ALS( userCol=\"userId\",  itemCol=\"movieId\",  ratingCol=\"rating\",  coldStartStrategy=\"nan\", maxIter=10, regParam=.1, rank=8)\n","model = als.fit(train)\n","\n","# Decision Tree\n","columns = [col for col in ratings_df.columns if col != 'rating']\n","assembler = VectorAssembler(inputCols=columns, outputCol=\"features\", handleInvalid=\"keep\")\n","assembled_df = assembler.transform(train).select(\"rating\",\"features\")\n","assembled_testSet = assembler.transform(test).select(\"rating\",\"features\")\n","dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol='rating', impurity=\"entropy\",maxDepth=len(columns)+2)\n","dt.fit(assembled_df)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["def create_binarised_output(ratings):\n","    binary = []\n","    for rating in ratings:\n","        if rating >= treshold:\n","            binary.append(1)\n","        else:\n","            binary.append(0)\n","    return binary\n","\n","\n","treshold = 3.5\n","\n","ALSprediction = model.transform(test).select('prediction').rdd.flatMap(lambda x : x ).collect()\n","\n","pipeline = Pipeline(stages=[dt])\n","pipeline = pipeline.fit(assembled_testSet)\n","prediction = pipeline.transform(assembled_testSet)\n","dtpredictions = prediction.select('prediction').rdd.flatMap(lambda x : x).collect()\n","\n","pred = [int(dtpredictions[i]) if math.isnan(ALSprediction[i]) else (float(dtpredictions[i])+ALSprediction[i])/2 for i in range(len(dtpredictions))]\n","\n","y = test.select('rating').rdd.flatMap(lambda x : x).collect()\n","\n","\n","# Calcuate RMSE\n","rmse = np.sqrt(mean_squared_error(y,pred))\n","print(rmse)\n","\n","y_binary = create_binarised_output(y)\n","pred_binary = create_binarised_output(pred)\n","\n","# Calculate Precision\n","precision = precision_score(y_binary, pred_binary)\n","print(\"Precision:\", precision)\n","\n","# Calculate recall\n","recall = recall_score(y_binary, pred_binary)\n","print(\"Recall:\", recall)\n","\n","# Calculate F-measure\n","f1 = f1_score(y_binary, pred_binary)\n","print(\"f1-score:\", f1)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
